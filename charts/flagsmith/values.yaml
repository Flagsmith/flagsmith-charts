api:
  image:
    repository: flagsmith/flagsmith-api
    tag: null  # defaults to .Chart.AppVersion
    imagePullPolicy: IfNotPresent
    imagePullSecrets: []
  # Note that if setting this to false, need to set
  # api.image.repository to flagsmith/flagsmith (or some other
  # repository hosting the image with combined frontend and backend)
  # and that the image tag exists (for flagsmith/flagsmith, >=2.10.0)
  #
  # Also, note that the ingress and service for the frontend remain
  # (unless explicitly switched off), but both are handled by the api
  # deployment's pods.
  separateApiAndFrontend: true
  replicacount: 1
  podAnnotations: {}
  resources: {}
  # limits:
  #   cpu: 500m
  #   memory: 500Mi
  # requests:
  #   cpu: 300m
  #   memory: 300Mi
  podLabels: {}
  extraEnv: {}
  # extraEnvFromSecret:
  #   NAME:
  #    secretName: mysecret
  #    secretKey: mykey
  extraEnvFromSecret: {}
  # See https://docs.flagsmith.com/deployment/locally-api#creating-a-secret-key
  secretKey: null
  nodeSelector: {}
  tolerations: []
  affinity: {}
  podSecurityContext: {}
  defaultPodSecurityContext:
    enabled: true
    # runAsNonRoot: true  # TODO: enable this, conditional on tag semver
    # runAsUser: 1000
    # runAsGroup: 1000
  livenessProbe:
    path: /health
    failureThreshold: 5
    initialDelaySeconds: 5
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 2
  readinessProbe:
    path: /health
    failureThreshold: 10
    initialDelaySeconds: 1
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 2
  dbWaiter:
    image:
      repository: willwill/wait-for-it
      tag: latest
      imagePullPolicy: IfNotPresent
    timeoutSeconds: 30

frontend:
  # Set this to `false` to switch off the frontend (deployment,
  # service and ingress). Set api.separateApiAndFrontend to false to
  # switch off the deployment but retain the service and ingress
  # pointing at the single Docker image that serves both.
  enabled: true
  image:
    repository: flagsmith/flagsmith-frontend
    tag: null  # defaults to .Chart.AppVersion
    imagePullPolicy: IfNotPresent
    imagePullSecrets: []
  replicacount: 1
  resources: {}
  # limits:
  #   cpu: 500m
  #   memory: 500Mi
  # requests:
  #   cpu: 300m
  #   memory: 300Mi
  apiProxy:
    enabled: true
  extraEnv: {}
  extraEnvFromSecret: {}
  nodeSelector: {}
  tolerations: []
  affinity: {}
  podSecurityContext: {}
  defaultPodSecurityContext:
    enabled: true
    # runAsNonRoot: true  # TODO: enable this, conditional on tag semver
    # runAsUser: 1000
    # runAsGroup: 1000
  livenessProbe:
    failureThreshold: 20
    initialDelaySeconds: 20
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 10
  readinessProbe:
    failureThreshold: 20
    initialDelaySeconds: 20
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 10

postgresql:
  enabled: true
  serviceAccount:
    enabled: true
  nameOverride: flagsmith-postgresql
  postgresqlDatabase: flagsmith
  postgresqlUsername: postgres
  postgresqlPassword: flagsmith

databaseExternal:
  enabled: false
  url: null
  type: postgres
  host: null
  port: 5432
  database: null
  username: null
  password: null
  urlFromExistingSecret:
    enabled: false
    name: null
    key: null

pgbouncer:
  enabled: false
  image:
    repository: bitnami/pgbouncer
    tag: 1.16.0
    imagePullPolicy: IfNotPresent
    imagePullSecrets: []
  replicaCount: 1
  podAnnotations: {}
  resources: {}
  podLabels: {}
  extraEnv: {}
  nodeSelector: {}
  tolerations: []
  affinity: {}
  podSecurityContext: {}
  defaultPodSecurityContext:
    enabled: true
    # runAsNonRoot: true
  securityContext: {}
  defaultSecurityContext:
    enabled: true
    allowPrivilegeEscalation: false
    capabilities:
      drop:
        - all

  livenessProbe:
    failureThreshold: 5
    initialDelaySeconds: 5
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 2
  readinessProbe:
    failureThreshold: 10
    initialDelaySeconds: 1
    periodSeconds: 10
    successThreshold: 1
    timeoutSeconds: 2

influxdb2:
  enabled: true
  adminUser:
    organization: "influxdata"
    bucket: "default"
    user: "admin"
    retention_policy: "0s"
    ## Leave empty to generate a random password and token.
    ## Or fill any of these values to use fixed values.
    password: ""
    token: ""
  persistence:
    enabled: false
    # storageClass: "-"
    # accessMode: ReadWriteOnce
    # size: 50Gi
  resources: {}
  nodeSelector: {}
  tolerations: []
  affinity: {}

influxdbExternal:
  enabled: false
  url: null
  bucket: null
  organization: null
  token: null
  tokenFromExistingSecret:
    enabled: false
    name: null
    key: null

service:
  api:
    type: ClusterIP
    port: 8000
    annotations: {}
  frontend:
    type: ClusterIP
    port: 8080
    annotations: {}

ingress:
  frontend:
    enabled: false
    annotations: {}
    ingressClassName: null
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths: []
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local
  api:
    enabled: false
    annotations: {}
    ingressClassName: null
    # kubernetes.io/ingress.class: nginx
    # kubernetes.io/tls-acme: "true"
    hosts:
      - host: chart-example.local
        paths: []
    tls: []
    #  - secretName: chart-example-tls
    #    hosts:
    #      - chart-example.local

# These tests just make non-destructive requests to the services in
# the cluster. Enabling this and running helm test is safe.
tests:
  # A test is enabled if both this and the specific test is enabled
  enabled: false
  api:
    enabled: true
    maxTime: 10
  frontend:
    enabled: true
    maxTime: 10

# These are used for integration testing the chart and the
# application. Enabling this will mean that data in a release is
# destroyed or corrupted if the tests are run.
_destructiveTests:
  # A test is enabled if both this and the specific test is enabled
  enabled: false
  testToken: test-e2e-token
  # This "monster" is in lieu of a specially constructed Docker image
  # that contains the code and dependencies for running the e2e
  # tests. It works by starting from a plain Ubuntu container,
  # retrieving the commit SHA from the API container, then cloning the
  # code from Github, installing dependencies, then running the tests.
  e2eMonster:
    enabled: true
    image:
      repository: ubuntu
      tag: jammy
      imagePullPolicy: IfNotPresent
    useFirefox: false
    resources:
      requests:
        memory: 1Gi
